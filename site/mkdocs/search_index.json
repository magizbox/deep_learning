{
    "docs": [
        {
            "location": "/", 
            "text": "Deep Learning\n\n\n\n\nDeep learning (also known as deep structured learning, hierarchical learning or deep machine learning) is a branch of machine learning based on a set of algorithms that attempt to model high-level abstractions in data by using a deep graph with multiple processing layers, composed of multiple linear and non-linear ...\n\n\nBooks\n\n\n\n\n\n\n\n\nCourses\n\n\n\n\n\n\n\n\nVideos", 
            "title": "Home"
        }, 
        {
            "location": "/#deep-learning", 
            "text": "Deep learning (also known as deep structured learning, hierarchical learning or deep machine learning) is a branch of machine learning based on a set of algorithms that attempt to model high-level abstractions in data by using a deep graph with multiple processing layers, composed of multiple linear and non-linear ...", 
            "title": "Deep Learning"
        }, 
        {
            "location": "/#books", 
            "text": "", 
            "title": "Books"
        }, 
        {
            "location": "/#courses", 
            "text": "", 
            "title": "Courses"
        }, 
        {
            "location": "/#videos", 
            "text": "", 
            "title": "Videos"
        }, 
        {
            "location": "/getting_started/", 
            "text": "Getting Started\n\n\nTo start with deep learning, you can choose either tensorflow, theano\n\n\nTensorflow\n\n\nInstall in Windows\n\n\nIn this section, I will introduce how to setup your tensorflow library working with GPU in Windows.\n\n\nMy environment is:\n\n\n\n\nWindows 8.1 Pro 64-bit\n\n\nGraphic Card: NVIDIA GeForce GTX 980\n\n\n\n\nWhat are missing?\n\n\n\n\nAnaconda\n\n\nCUDA Toolkit 8.0 (cuda_8.0.44_windows.exe)\n\n\nCUDNN - CUDA for Deep Neural Networks (cudnn-8.0-windows7-x64-v5.1.zip)\n\n\ntensorflow package\n\n\n\n\nAnaconda\n\n\nAnaconda is the leading open data science platform powered by Python. The open source version of Anaconda is a high performance distribution of Python and R and includes over 100 of the most popular Python, R and Scala packages for data science.\n\n\nStep 1: Download the \nAnaconda installer\n\n\nStep 2: Double click the Anaconda installer and follow the prompts to install to the default location.\n\n\nAfter a successful installation you will see output like this:\n\n\n\n\nCUDA Toolkit 8.0\n\n\nThe NVIDIA CUDA Toolkit provides a comprehensive development environment for C and C++ developers building GPU-accelerated applications. The CUDA Toolkit includes a compiler for NVIDIA GPUs, math libraries, and tools for debugging and optimizing the performance of your applications. You\u2019ll also find programming guides, user manuals, API reference, and other documentation to help you get started quickly accelerating your application with GPUs.\n\n\nStep 1: Verify the system has a CUDA-capable GPU.\n\n\nStep 2: Download the \nNVIDIA CUDA Toolkit\n.\n\n\nStep 3: Install the NVIDIA CUDA Toolkit.\n\n\nStep 4: Test that the installed software runs correctly and communicates with the hardware.\n\n\n\n\ncuDNN\n\n\nThe NVIDIA CUDA Deep Neural Network library (cuDNN) is a GPU-accelerated library of primitives for deep neural networks. cuDNN provides highly tuned implementations for standard routines such as forward and backward convolution, pooling, normalization, and activation layers. cuDNN is part of the NVIDIA Deep Learning SDK.\n\n\nStep 1: Register an NVIDIA developer account\n\n\nStep 2: Download \ncuDNN v5.1\n, you will get file like that \ncudnn-8.0-windows7-x64-v5.1.zip\n\n\n\n\nStep 3: Copy CUDNN files to CUDA install\n\n\nExtract your \ncudnn-8.0-windows7-x64-v5.1.zip\n file, and copy files to corresponding CUDA folder\n\n\nIn my environment, CUDA installed in \nC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\n, you must copy append three folders \nbin\n, \ninclude\n, \nlib\n\n\n\n\nInstall Tensorflow Package\n\n\nCPU TensorFlow environment\n\n\nconda create --name tensorflow python=3.5\nactivate tensorflow\nconda install -y jupyter scipy\npip install tensorflow\n\n\n\n\nGPU TensorFlow environment\n\n\nconda create --name tensorflow-gpu python=3.5\nactivate tensorflow-gpu\nconda install -y jupyter scipy\npip install tensorflow-gpu\n\n\n\n\nReferences\n\n\n\n\nUsing TensorFlow in Windows with a GPU, \nhttp://www.heatonresearch.com/2017/01/01/tensorflow-windows-gpu.html\n\n\nsentdex, Installing CPU and GPU TensorFlow on Windows, \nhttps://www.youtube.com/watch?v=r7-WPbx8VuY\n\n\n\n\nword2vec Example\n\n\nStep 1: Download word2vec example from \ngithub\n\n\n$ dir\n\n02/06/2017  11:45    \nDIR\n          .\n02/06/2017  11:45    \nDIR\n          ..\n02/06/2017  10:12             9,144 word2vec_basic.py\n\n\n\n\nStep 2: Run \nword2vec_basic\n example\n\n\n$ activate tensorflow-gpu\n$ python word2vec_basic.py\n\nFound and verified text8.zip\nData size 17005207\nMost common words (+UNK) [['UNK', 418391], ('the', 1061396), ('of', 593677), ('and', 416629), ('one', 411764)]\nSample data [5241, 3082, 12, 6, 195, 2, 3136, 46, 59, 156] ['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against']\n3082 originated -\n 5241 anarchism\n3082 originated -\n 12 as\n12 as -\n 6 a\n12 as -\n 3082 originated\n6 a -\n 195 term\n6 a -\n 12 as\n195 term -\n 2 of\n195 term -\n 6 a\nInitialized\nAverage loss at step  0 :  288.173675537\nNearest to its: nasl, tinkering, derivational, yachts, emigrated, fatalism, kingston, kochi,\nNearest to into: streetcars, neglecting, deutschlands, lecture, realignment, bligh, donau, medalists,\nNearest to state: canterbury, exceptions, disaffection, crete, westernmost, earthly, organize, richland,\n...", 
            "title": "Getting Started"
        }, 
        {
            "location": "/getting_started/#getting-started", 
            "text": "To start with deep learning, you can choose either tensorflow, theano", 
            "title": "Getting Started"
        }, 
        {
            "location": "/getting_started/#tensorflow", 
            "text": "", 
            "title": "Tensorflow"
        }, 
        {
            "location": "/getting_started/#install-in-windows", 
            "text": "In this section, I will introduce how to setup your tensorflow library working with GPU in Windows.  My environment is:   Windows 8.1 Pro 64-bit  Graphic Card: NVIDIA GeForce GTX 980   What are missing?   Anaconda  CUDA Toolkit 8.0 (cuda_8.0.44_windows.exe)  CUDNN - CUDA for Deep Neural Networks (cudnn-8.0-windows7-x64-v5.1.zip)  tensorflow package", 
            "title": "Install in Windows"
        }, 
        {
            "location": "/getting_started/#anaconda", 
            "text": "Anaconda is the leading open data science platform powered by Python. The open source version of Anaconda is a high performance distribution of Python and R and includes over 100 of the most popular Python, R and Scala packages for data science.  Step 1: Download the  Anaconda installer  Step 2: Double click the Anaconda installer and follow the prompts to install to the default location.  After a successful installation you will see output like this:", 
            "title": "Anaconda"
        }, 
        {
            "location": "/getting_started/#cuda-toolkit-80", 
            "text": "The NVIDIA CUDA Toolkit provides a comprehensive development environment for C and C++ developers building GPU-accelerated applications. The CUDA Toolkit includes a compiler for NVIDIA GPUs, math libraries, and tools for debugging and optimizing the performance of your applications. You\u2019ll also find programming guides, user manuals, API reference, and other documentation to help you get started quickly accelerating your application with GPUs.  Step 1: Verify the system has a CUDA-capable GPU.  Step 2: Download the  NVIDIA CUDA Toolkit .  Step 3: Install the NVIDIA CUDA Toolkit.  Step 4: Test that the installed software runs correctly and communicates with the hardware.", 
            "title": "CUDA Toolkit 8.0"
        }, 
        {
            "location": "/getting_started/#cudnn", 
            "text": "The NVIDIA CUDA Deep Neural Network library (cuDNN) is a GPU-accelerated library of primitives for deep neural networks. cuDNN provides highly tuned implementations for standard routines such as forward and backward convolution, pooling, normalization, and activation layers. cuDNN is part of the NVIDIA Deep Learning SDK.  Step 1: Register an NVIDIA developer account  Step 2: Download  cuDNN v5.1 , you will get file like that  cudnn-8.0-windows7-x64-v5.1.zip   Step 3: Copy CUDNN files to CUDA install  Extract your  cudnn-8.0-windows7-x64-v5.1.zip  file, and copy files to corresponding CUDA folder  In my environment, CUDA installed in  C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0 , you must copy append three folders  bin ,  include ,  lib", 
            "title": "cuDNN"
        }, 
        {
            "location": "/getting_started/#install-tensorflow-package", 
            "text": "CPU TensorFlow environment  conda create --name tensorflow python=3.5\nactivate tensorflow\nconda install -y jupyter scipy\npip install tensorflow  GPU TensorFlow environment  conda create --name tensorflow-gpu python=3.5\nactivate tensorflow-gpu\nconda install -y jupyter scipy\npip install tensorflow-gpu  References   Using TensorFlow in Windows with a GPU,  http://www.heatonresearch.com/2017/01/01/tensorflow-windows-gpu.html  sentdex, Installing CPU and GPU TensorFlow on Windows,  https://www.youtube.com/watch?v=r7-WPbx8VuY", 
            "title": "Install Tensorflow Package"
        }, 
        {
            "location": "/getting_started/#word2vec-example", 
            "text": "Step 1: Download word2vec example from  github  $ dir\n\n02/06/2017  11:45     DIR           .\n02/06/2017  11:45     DIR           ..\n02/06/2017  10:12             9,144 word2vec_basic.py  Step 2: Run  word2vec_basic  example  $ activate tensorflow-gpu\n$ python word2vec_basic.py\n\nFound and verified text8.zip\nData size 17005207\nMost common words (+UNK) [['UNK', 418391], ('the', 1061396), ('of', 593677), ('and', 416629), ('one', 411764)]\nSample data [5241, 3082, 12, 6, 195, 2, 3136, 46, 59, 156] ['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against']\n3082 originated -  5241 anarchism\n3082 originated -  12 as\n12 as -  6 a\n12 as -  3082 originated\n6 a -  195 term\n6 a -  12 as\n195 term -  2 of\n195 term -  6 a\nInitialized\nAverage loss at step  0 :  288.173675537\nNearest to its: nasl, tinkering, derivational, yachts, emigrated, fatalism, kingston, kochi,\nNearest to into: streetcars, neglecting, deutschlands, lecture, realignment, bligh, donau, medalists,\nNearest to state: canterbury, exceptions, disaffection, crete, westernmost, earthly, organize, richland,\n...", 
            "title": "word2vec Example"
        }, 
        {
            "location": "/introduction/", 
            "text": "Modern Practical Deep Networks\n\n\n\n\nFeedforward Deep Networks\n\n\nRegularization\n\n\nOptimization for Training Deep Models\n\n\nConvolutional Networks\n\n\nSequence Modeling: Recurrent and Recursive Nets\n\n\nApplications\n\n\n\n\nDeep Learning Research\n\n\n\n\nStructured Probabilistic Models for Deep Learning\n\n\nMonte Carlo Methods\n\n\nLinear Factor Models and Auto-Encoders\n\n\nRepresentation Learning\n\n\nThe Manifold Perspective on Representation Learning\n\n\nConfronting the Partition Function\n\n\nApproximate Inference\n\n\nDeep Generative Models\n\n\n\n\nSlide\n\n\n\n\nAndrew Ng, Deep Learning, http://www.slideshare.net/mobile/ExtractConf/andrew-ng-chief-scientist-at-baidu\n\n\n\n\nCompare Deep Learning Framework\n\n\nhttps://github.com/zer0n/deepframeworks/blob/master/README.md\n\n\nPapers\n\n\nAwesome Deep Learning Papers\n\n\nDeep Learning Q\nA\n\n\nDeep Learning Q\nA \n1\n\n\n\n\nWhat is an auto-encoder? Why do we \"auto-encode\"? Hint: it's really a misnomer.\n\n\nWhat is a Boltzmann Machine? Why a Boltzmann Machine?\n\n\nWhy do we use sigmoid for an output function? Why tanh? Why not cosine? Why any function in particular?\n\n\nWhy are CNNs used primarily in imaging and not so much other tasks?\n\n\nExplain backpropagation. Seriously. To the target audience described above.\n\n\nIs it OK to connect from a Layer 4 output back to a Layer 2 input?\n\n\n\n\nA data-scientist person recently put up a YouTube video explaining that the essential difference between a Neural Network and a Deep Learning network is that the former is trained from output back to input, while the latter is trained from input toward output. Do you agree? Explain.\n\n\n\n\n\n\nCan you derive the back-propagation and weights update?\n\n\n\n\nExtend the above question to non-trivial layers such as convolutional layers, pooling layers, etc.\n\n\nHow to implement dropout\n\n\nYour intuition when and why some tricks such as max pooling, ReLU, maxout, etc. work. There are no right answers but it helps to understand your thoughts and research experience.\n\n\nCan youabstract the forward, backward, update operations as matrix operations, to leverage BLAS and GPU?\n\n\n\n\nIntro to Deep Learning\n\n\n\n\nWhat is deep learning?\n\n\n\nAccording to wikipedia \n1\n\n\nDeep learning\n \u00a0is a branch of machine learning based on a set of algorithms that \nattempt to model high-level abstractions\n in data by \nusing model architectures\n, with \ncomplex structures\n or otherwise, \ncomposed of multiple non-linear transformations.\n\n\nDeep learning is part of a broader family of machine learning methods based on \nlearning representations\n of data.\n\nAn observation (e.g., an image) can be represented in many ways such as a vector of intensity values per pixel, or in a more abstract way as a set of edges, regions of particular shape, etc.. Some representations make it easier to learn tasks (e.g., face recognition or facial expression recognition) from examples.\n\nOne of the promises of deep learning is replacing \nhandcrafted features\n with efficient algorithms for unsupervised or semi-supervised feature learning and hierarchical feature extraction.\n\n\n\nTraditional Model vs Deep Learning\n\n\n\nIn \ntraditional models\n, we must extract features by hand, after that we train these features with some classifiers\n\n\n\n\nWith \ndeep learning\n, we can learn representation of objects as well as its classifiers.\n\n\n\n\nHierarchy of representations with increasing level of abstraction. Each stage is a kind of trainable feature transform.\n\n\nImage recognition\n\n\npixel \n edge \n texton \n motif \n part \n object\n\n\nText\n\n\ncharacter \n word \n word group \n clause \n sentence \n story\n\n\nSpeech\n\n\nsample \n spectral band \n sound \n ... \n phone \n phoneme \n word\n\n\nDemos and Applications\n\n\n\nYann Lecun with ImageNetOnline Learning Demo in his deep learning class \n2\n.\u00a0This program auto learn new object when he pointed camera to it\n\n\n\n\nVoice recognition systems like Apple Siri, Google Now and Windows Cortana all use deep learning \n3\n\n\n\n\nFacebook's DeepFace Software Can Match Faces With 97.25% Accuracy \n4\n\n\n\n\nUseful Resources\n\n\n\n\n\nIntroduction about Deep Learning, http://colah.github.io/\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u00a0\nDeep Learning, wikipedia\n\n\n\n\n\n\n\nDeep Learning Course of Yann Lecu, Week 1\n\n\n\n\n\n\n\nMeet The Guy Who Helped Google Beat Apple's Siri\n\n\n\n\n\n\n\u00a0\nFacebook's DeepFace Software Can Match Faces With 97.25% Accuracy\n\n\n\n\n\n\n\n\n\n\nTensorFlow\n\n\n\n\nTensorFlow\u2122 \n2\n is an open source software library for numerical computation using data flow graphs. Nodes in the graph represent mathematical operations, while the graph edges represent the multidimensional data arrays (tensors) communicated between them. The flexible architecture allows you to deploy computation to one or more CPUs or GPUs in a desktop, server, or mobile device with a single API. TensorFlow was originally developed by researchers and engineers working on the Google Brain Team within Google's Machine Intelligence research organization for the purposes of conducting machine learning and deep neural networks research, but the system is general enough to be applicable in a wide variety of other domains as well.\n\n\nGetting Started\n\n\nLinux\n, \nMac\n, \nWindows\n\n\nWindows \n1\n\n\n[code lang=\"shell\"]\ndocker-machine ssh default\ndocker run -it b.gcr.io/tensorflow/tensorflow\n[/code]\n\n\nResources\n\n\n\n\nTensorFlow Explained by Jeff Dean (\nvideo\n)\n\n\n\n\nArchitectures\n\n\nAccording to Yann Lecun \n1\n, there are three types of deep architectures: feed-forward, feed-back and bi-directional.\n\n\nFeed-Forwards\n\n\n\nMultilayer Neural Nets \n2\n\n\n\nA multilayer perceptron (MLP) is a feedforward artificial neural network model that maps sets of input data onto a set of appropriate outputs. A MLP consists of multiple layers of nodes in a directed graph, with each layer fully connected to the next one. Except for the input nodes, each node is a neuron (or processing element) with a nonlinear activation function.\n\n\n\n\ntask: any supervised learning pattern recognition process\n\n\nConvolutional Neural Nets \n3\n\n\n\nIn machine learning, a convolutional neural network (CNN, or ConvNet) is a type of feed-forward artificial neural network where the individual neurons are tiled in such a way that they respond to overlapping regions in the visual field.Convolutional networks were inspired by biological processes and are variations of multilayer perceptrons which are designed to use minimal amounts of preprocessing. They are widely used models for image and video recognition.\n\n\n\n\ntask:\u00a0Computer Vision\n\n\nFeed-Back\n\n\n\nStacked sparse coding\n\n\n\nDeconvolutional nets\n\n\n\nBi-Directional\n\n\n\nRecurrent neural network \n4\n\n\n\nA recurrent neural network (RNN) is a class of artificial neural network where connections between units form a directed cycle. This creates an internal state of the network which allows it to exhibit dynamic temporal behavior.\n\n\n\n\nTask: \nWord Embeddings\n\n\nDeep Boltzmann\u00a0Network\n\n\n\n\n\nStacked auto-encoders \n5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://www.slideshare.net/yandex/yann-le-cun\n\n\n\n\n\n\nhttps://en.wikipedia.org/wiki/Multilayer_perceptron\n\n\n\n\n\n\n\u00a0\nhttps://en.wikipedia.org/wiki/Convolutional_neural_network\n\n\n\n\n\n\n\nRecurrent neural network\n\n\n\n\n\n\n\nhttp://ufldl.stanford.edu/wiki/index.php/Stacked_Autoencoders\n\n\n\n\n\n\n\n\n\n\nDeep Reinforcement Learning\n\n\nDavid Silver (Google DeepMind) - Deep Reinforcement Learning\n\n\nRecurrent Neural Networks\n\n\nA recurrent neural network (RNN) is a class of artificial neural network where connections between units form a directed cycle. This creates an internal state of the network which allows it to exhibit dynamic temporal behavior. Unlike feedforward neural networks, RNNs can use their internal memory to process arbitrary sequences of inputs. This makes them applicable to tasks such as unsegmented connected handwriting recognition or speech recognition\n\n\n1. Applications \n1\n\n\n1.1 Sequence-to-sequence language translation \n2\n\n\n\n\n1.2 Generate image caption\n\n\n\n\n1.3 Translate videos to sentences\n\n\n\n\n2. Challenges\n\n\n\n\nBag of Words Meets Bags of Popcorn\n\n\n\n\n3. Tutorials\n\n\n\n\nAnyone Can Learn To Code an LSTM-RNN in Python (Part 1: RNN)\n\n\nThe Unreasonable Effectiveness of Recurrent Neural Networks\n\n\n\n\n4. Library\n\n\n\n\nneuraltalk2\n \n(realtime demo)[https://vimeo.com/146492001]\n\n\n\n\n\n\n\n\n\n\n\n\nRecurrent Neural Network\n\n\n\n\n\n\nGeneral Sequence Learning using Recurrent Neural Networks", 
            "title": "Introduction"
        }, 
        {
            "location": "/introduction/#modern-practical-deep-networks", 
            "text": "Feedforward Deep Networks  Regularization  Optimization for Training Deep Models  Convolutional Networks  Sequence Modeling: Recurrent and Recursive Nets  Applications", 
            "title": "Modern Practical Deep Networks"
        }, 
        {
            "location": "/introduction/#deep-learning-research", 
            "text": "Structured Probabilistic Models for Deep Learning  Monte Carlo Methods  Linear Factor Models and Auto-Encoders  Representation Learning  The Manifold Perspective on Representation Learning  Confronting the Partition Function  Approximate Inference  Deep Generative Models", 
            "title": "Deep Learning Research"
        }, 
        {
            "location": "/introduction/#slide", 
            "text": "Andrew Ng, Deep Learning, http://www.slideshare.net/mobile/ExtractConf/andrew-ng-chief-scientist-at-baidu   Compare Deep Learning Framework  https://github.com/zer0n/deepframeworks/blob/master/README.md", 
            "title": "Slide"
        }, 
        {
            "location": "/introduction/#papers", 
            "text": "Awesome Deep Learning Papers", 
            "title": "Papers"
        }, 
        {
            "location": "/introduction/#deep-learning-qa", 
            "text": "Deep Learning Q A  1   What is an auto-encoder? Why do we \"auto-encode\"? Hint: it's really a misnomer.  What is a Boltzmann Machine? Why a Boltzmann Machine?  Why do we use sigmoid for an output function? Why tanh? Why not cosine? Why any function in particular?  Why are CNNs used primarily in imaging and not so much other tasks?  Explain backpropagation. Seriously. To the target audience described above.  Is it OK to connect from a Layer 4 output back to a Layer 2 input?   A data-scientist person recently put up a YouTube video explaining that the essential difference between a Neural Network and a Deep Learning network is that the former is trained from output back to input, while the latter is trained from input toward output. Do you agree? Explain.    Can you derive the back-propagation and weights update?   Extend the above question to non-trivial layers such as convolutional layers, pooling layers, etc.  How to implement dropout  Your intuition when and why some tricks such as max pooling, ReLU, maxout, etc. work. There are no right answers but it helps to understand your thoughts and research experience.  Can youabstract the forward, backward, update operations as matrix operations, to leverage BLAS and GPU?", 
            "title": "Deep Learning Q&amp;A"
        }, 
        {
            "location": "/introduction/#intro-to-deep-learning", 
            "text": "", 
            "title": "Intro to Deep Learning"
        }, 
        {
            "location": "/introduction/#tensorflow", 
            "text": "TensorFlow\u2122  2  is an open source software library for numerical computation using data flow graphs. Nodes in the graph represent mathematical operations, while the graph edges represent the multidimensional data arrays (tensors) communicated between them. The flexible architecture allows you to deploy computation to one or more CPUs or GPUs in a desktop, server, or mobile device with a single API. TensorFlow was originally developed by researchers and engineers working on the Google Brain Team within Google's Machine Intelligence research organization for the purposes of conducting machine learning and deep neural networks research, but the system is general enough to be applicable in a wide variety of other domains as well.", 
            "title": "TensorFlow"
        }, 
        {
            "location": "/introduction/#getting-started", 
            "text": "Linux ,  Mac ,  Windows  Windows  1  [code lang=\"shell\"]\ndocker-machine ssh default\ndocker run -it b.gcr.io/tensorflow/tensorflow\n[/code]", 
            "title": "Getting Started"
        }, 
        {
            "location": "/introduction/#resources", 
            "text": "TensorFlow Explained by Jeff Dean ( video )", 
            "title": "Resources"
        }, 
        {
            "location": "/introduction/#architectures", 
            "text": "According to Yann Lecun  1 , there are three types of deep architectures: feed-forward, feed-back and bi-directional.", 
            "title": "Architectures"
        }, 
        {
            "location": "/introduction/#deep-reinforcement-learning", 
            "text": "David Silver (Google DeepMind) - Deep Reinforcement Learning", 
            "title": "Deep Reinforcement Learning"
        }, 
        {
            "location": "/introduction/#recurrent-neural-networks", 
            "text": "A recurrent neural network (RNN) is a class of artificial neural network where connections between units form a directed cycle. This creates an internal state of the network which allows it to exhibit dynamic temporal behavior. Unlike feedforward neural networks, RNNs can use their internal memory to process arbitrary sequences of inputs. This makes them applicable to tasks such as unsegmented connected handwriting recognition or speech recognition", 
            "title": "Recurrent Neural Networks"
        }, 
        {
            "location": "/introduction/#1-applications-1", 
            "text": "", 
            "title": "1. Applications 1"
        }, 
        {
            "location": "/introduction/#11-sequence-to-sequence-language-translation-2", 
            "text": "", 
            "title": "1.1 Sequence-to-sequence language translation 2"
        }, 
        {
            "location": "/introduction/#12-generate-image-caption", 
            "text": "", 
            "title": "1.2 Generate image caption"
        }, 
        {
            "location": "/introduction/#13-translate-videos-to-sentences", 
            "text": "", 
            "title": "1.3 Translate videos to sentences"
        }, 
        {
            "location": "/introduction/#2-challenges", 
            "text": "Bag of Words Meets Bags of Popcorn", 
            "title": "2. Challenges"
        }, 
        {
            "location": "/introduction/#3-tutorials", 
            "text": "Anyone Can Learn To Code an LSTM-RNN in Python (Part 1: RNN)  The Unreasonable Effectiveness of Recurrent Neural Networks", 
            "title": "3. Tutorials"
        }, 
        {
            "location": "/introduction/#4-library", 
            "text": "neuraltalk2   (realtime demo)[https://vimeo.com/146492001]       Recurrent Neural Network    General Sequence Learning using Recurrent Neural Networks", 
            "title": "4. Library"
        }, 
        {
            "location": "/rnn/", 
            "text": "What are RNNs?\n\n\nThe idea behind RNNs is to make use of sequential information. In a traditional neural network we assume that all inputs (and outputs) are independent of each other. But for many tasks that\u2019s a very bad idea. If you want to predict the next word in a sentence you better know which words came before it. RNNs are called recurrent because they perform the same task for every element of a sequence, with the output being depended on the previous computations. Another way to think about RNNs is that they have a \u201cmemory\u201d which captures information about what has been calculated so far. In theory RNNs can make use of information in arbitrarily long sequences, but in practice they are limited to looking back only a few steps (more on this later). Here is what a typical RNN looks like:\n\n\n\n\n\n\nA recurrent neural network and the unfolding in time of the computation involved in its forward computation\n\n\n\n\nA recurrent neural network and the unfolding in time of the computation involved in its forward computation. Source: Nature\nThe above diagram shows a RNN being unrolled (or unfolded) into a full network. By unrolling we simply mean that we write out the network for the complete sequence. For example, if the sequence we care about is a sentence of 5 words, the network would be unrolled into a 5-layer neural network, one layer for each word. The formulas that govern the computation happening in a RNN are as follows:\n\n\n\n\n\n\nx_t\n is the input at time step \nt\n. For example, \nx_1\n could be a one-hot vector corresponding to the second word of a sentence.\n\n\n\n\ns_t\n is the hidden state at time step \nt\n. It\u2019s the \u201cmemory\u201d of the network. \ns_t\n is calculated based on the previous hidden state and the input at the current step: \ns_t=f(Ux_t + Ws_{t-1})\n. The function \nf\n usually is a nonlinearity such as \ntanh\n or \nReLU\n.  \ns_{-1}\n, which is required to calculate the first hidden state, is typically initialized to all zeroes.\n\n\n\n\no_t\n is the output at step \nt\n. For example, if we wanted to predict the next word in a sentence it would be a vector of probabilities across our vocabulary. \no_t = \\mathrm{softmax}(Vs_t)\n.\n\n\n\n\nThere are a few things to note here:\n\n\n\n\nYou can think of the hidden state \ns_t\n as the memory of the network. \ns_t\n captures information about what happened in all the previous time steps. The output at step \no_t\n is calculated solely based on the memory at time \nt\n. As briefly mentioned above, it\u2019s a bit more complicated  in practice because \ns_t\n typically can\u2019t capture information from too many time steps ago.\n\n\nUnlike a traditional deep neural network, which uses different parameters at each layer, a RNN shares the same parameters (\nU\n, \nV\n, \nW\n above) across all steps. This reflects the fact that we are performing the same task at each step, just with different inputs. This greatly reduces the total number of parameters we need to learn.\n\n\nThe above diagram has outputs at each time step, but depending on the task this may not be necessary. For example, when predicting the sentiment of a sentence we may only care about the final output, not the sentiment after each word. Similarly, we may not need inputs at each time step. The main feature of an RNN is its hidden state, which captures some information about a sequence.\n\n\n\n\nWhat can RNNs do?\n\n\nRNNs have shown great success in many NLP tasks. At this point I should mention that the most commonly used type of RNNs are LSTMs, which are much better at capturing long-term dependencies than vanilla RNNs are. But don\u2019t worry, LSTMs are essentially the same thing as the RNN we will develop in this tutorial, they just have a different way of computing the hidden state. We\u2019ll cover LSTMs in more detail in a later post. Here are some example applications of RNNs in NLP (by non means an exhaustive list).\n\n\nLanguage Modeling and Generating Text\n\n\nGiven a sequence of words we want to predict the probability of each word given the previous words. Language Models allow us to measure how likely a sentence is, which is an important input for Machine Translation (since high-probability sentences are typically correct). A side-effect of being able to predict the next word is that we get a generative model, which allows us to generate new text by sampling from the output probabilities. And depending on what our training data is we can generate all kinds of stuff. In Language Modeling our input is typically a sequence of words (encoded as one-hot vectors for example), and our output is the sequence of predicted words. When training the network we set o_t = x_{t+1} since we want the output at step t to be the actual next word.\n\n\nResearch papers about Language Modeling and Generating Text:\n\n\n\n\nRecurrent neural network based language model\n\n\nExtensions of Recurrent neural network based language model\n\n\nGenerating Text with Recurrent Neural Networks\n\n\n\n\nMachine Translation\n\n\nMachine Translation is similar to language modeling in that our input is a sequence of words in our source language (e.g. German). We want to output a sequence of words in our target language (e.g. English). A key difference is that our output only starts after we have seen the complete input, because the first word of our translated sentences may require information captured from the complete input sequence.\n\n\nRNN for Machine Translation\n\n\nRNN for Machine Translation. Image Source: http://cs224d.stanford.edu/lectures/CS224d-Lecture8.pdf\n\n\nResearch papers about Machine Translation:\n\n\n\n\nA Recursive Recurrent Neural Network for Statistical Machine Translation\n\n\nSequence to Sequence Learning with Neural Networks\n\n\nJoint Language and Translation Modeling with Recurrent Neural Networks\n\n\n\n\nSpeech Recognition\n\n\nGiven an input sequence of acoustic signals from a sound wave, we can predict a sequence of phonetic segments together with their probabilities.\n\n\nResearch papers about Speech Recognition:\n\n\nTowards End-to-End Speech Recognition with Recurrent Neural Networks\n\n\nGenerating Image Descriptions\n\n\nTogether with convolutional Neural Networks, RNNs have been used as part of a model to generate descriptions for unlabeled images. It\u2019s quite amazing how well this seems to work. The combined model even aligns the generated words with features found in the images.\n\n\nDeep Visual-Semantic Alignments for Generating Image Descriptions\nDeep Visual-Semantic Alignments for Generating Image Descriptions. Source: http://cs.stanford.edu/people/karpathy/deepimagesent/\n\n\nTraining RNNs\n\n\nTraining a RNN is similar to training a traditional Neural Network. We also use the backpropagation algorithm, but with a little twist. Because the parameters are shared by all time steps in the network, the gradient at each output depends not only on the calculations of the current time step, but also the previous time steps. For example, in order to calculate the gradient at t=4 we would need to backpropagate 3 steps and sum up the gradients. This is called Backpropagation Through Time (BPTT). If this doesn\u2019t make a whole lot of sense yet, don\u2019t worry, we\u2019ll have a whole post on the gory details. For now, just be aware of the fact that vanilla RNNs trained with BPTT have difficulties learning long-term dependencies (e.g. dependencies between steps that are far apart) due to what is called the vanishing/exploding gradient problem. There exists some machinery to deal with these problems, and certain types of RNNs (like LSTMs) were specifically designed to get around them.\n\n\nRNN Extensions\n\n\nOver the years researchers have developed more sophisticated types of RNNs to deal with some of the shortcomings of the vanilla RNN model. We will cover them in more detail in a later post, but I want this section to serve as a brief overview so that you are familiar with the taxonomy of models.\n\n\nBidirectional RNNs are based on the idea that the output at time t may not only depend on the previous elements in the sequence, but also future elements. For example, to predict a missing word in a sequence you want to look at both the left and the right context. Bidirectional RNNs are quite simple. They are just two RNNs stacked on top of each other. The output is then computed based on the hidden state of both RNNs.\n\n\nBidirectional RNN\n\n\nDeep (Bidirectional) RNNs are similar to Bidirectional RNNs, only that we now have multiple layers per time step. In practice this gives us a higher learning capacity (but we also need a lot of training data).\n\n\nDeep Bidirectional RNN\n\n\nLSTM networks are quite popular these days and we briefly talked about them above. LSTMs don\u2019t have a fundamentally different architecture from RNNs, but they use a different function to compute the hidden state. The memory in LSTMs are called cells and you can think of them as black boxes that take as input the previous state h_{t-1} and current input x_t. Internally these cells  decide what to keep in (and what to erase from) memory. They then combine the previous state, the current memory, and the input. It turns out that these types of units are very efficient at capturing long-term dependencies. LSTMs can be quite confusing in the beginning but if you\u2019re interested in learning more this post has an excellent explanation.\n\n\nConclusion\n\n\nSo far so good. I hope you\u2019ve gotten a basic understanding of what RNNs are and what they can do. In the next post we\u2019ll implement a first version of our language model RNN using Python and Theano. Please leave questions in the comments!", 
            "title": "Recurent Neural Network"
        }, 
        {
            "location": "/rnn/#what-are-rnns", 
            "text": "The idea behind RNNs is to make use of sequential information. In a traditional neural network we assume that all inputs (and outputs) are independent of each other. But for many tasks that\u2019s a very bad idea. If you want to predict the next word in a sentence you better know which words came before it. RNNs are called recurrent because they perform the same task for every element of a sequence, with the output being depended on the previous computations. Another way to think about RNNs is that they have a \u201cmemory\u201d which captures information about what has been calculated so far. In theory RNNs can make use of information in arbitrarily long sequences, but in practice they are limited to looking back only a few steps (more on this later). Here is what a typical RNN looks like:    A recurrent neural network and the unfolding in time of the computation involved in its forward computation   A recurrent neural network and the unfolding in time of the computation involved in its forward computation. Source: Nature\nThe above diagram shows a RNN being unrolled (or unfolded) into a full network. By unrolling we simply mean that we write out the network for the complete sequence. For example, if the sequence we care about is a sentence of 5 words, the network would be unrolled into a 5-layer neural network, one layer for each word. The formulas that govern the computation happening in a RNN are as follows:    x_t  is the input at time step  t . For example,  x_1  could be a one-hot vector corresponding to the second word of a sentence.   s_t  is the hidden state at time step  t . It\u2019s the \u201cmemory\u201d of the network.  s_t  is calculated based on the previous hidden state and the input at the current step:  s_t=f(Ux_t + Ws_{t-1}) . The function  f  usually is a nonlinearity such as  tanh  or  ReLU .   s_{-1} , which is required to calculate the first hidden state, is typically initialized to all zeroes.   o_t  is the output at step  t . For example, if we wanted to predict the next word in a sentence it would be a vector of probabilities across our vocabulary.  o_t = \\mathrm{softmax}(Vs_t) .   There are a few things to note here:   You can think of the hidden state  s_t  as the memory of the network.  s_t  captures information about what happened in all the previous time steps. The output at step  o_t  is calculated solely based on the memory at time  t . As briefly mentioned above, it\u2019s a bit more complicated  in practice because  s_t  typically can\u2019t capture information from too many time steps ago.  Unlike a traditional deep neural network, which uses different parameters at each layer, a RNN shares the same parameters ( U ,  V ,  W  above) across all steps. This reflects the fact that we are performing the same task at each step, just with different inputs. This greatly reduces the total number of parameters we need to learn.  The above diagram has outputs at each time step, but depending on the task this may not be necessary. For example, when predicting the sentiment of a sentence we may only care about the final output, not the sentiment after each word. Similarly, we may not need inputs at each time step. The main feature of an RNN is its hidden state, which captures some information about a sequence.", 
            "title": "What are RNNs?"
        }, 
        {
            "location": "/rnn/#what-can-rnns-do", 
            "text": "RNNs have shown great success in many NLP tasks. At this point I should mention that the most commonly used type of RNNs are LSTMs, which are much better at capturing long-term dependencies than vanilla RNNs are. But don\u2019t worry, LSTMs are essentially the same thing as the RNN we will develop in this tutorial, they just have a different way of computing the hidden state. We\u2019ll cover LSTMs in more detail in a later post. Here are some example applications of RNNs in NLP (by non means an exhaustive list).", 
            "title": "What can RNNs do?"
        }, 
        {
            "location": "/rnn/#language-modeling-and-generating-text", 
            "text": "Given a sequence of words we want to predict the probability of each word given the previous words. Language Models allow us to measure how likely a sentence is, which is an important input for Machine Translation (since high-probability sentences are typically correct). A side-effect of being able to predict the next word is that we get a generative model, which allows us to generate new text by sampling from the output probabilities. And depending on what our training data is we can generate all kinds of stuff. In Language Modeling our input is typically a sequence of words (encoded as one-hot vectors for example), and our output is the sequence of predicted words. When training the network we set o_t = x_{t+1} since we want the output at step t to be the actual next word.  Research papers about Language Modeling and Generating Text:   Recurrent neural network based language model  Extensions of Recurrent neural network based language model  Generating Text with Recurrent Neural Networks", 
            "title": "Language Modeling and Generating Text"
        }, 
        {
            "location": "/rnn/#machine-translation", 
            "text": "Machine Translation is similar to language modeling in that our input is a sequence of words in our source language (e.g. German). We want to output a sequence of words in our target language (e.g. English). A key difference is that our output only starts after we have seen the complete input, because the first word of our translated sentences may require information captured from the complete input sequence.  RNN for Machine Translation  RNN for Machine Translation. Image Source: http://cs224d.stanford.edu/lectures/CS224d-Lecture8.pdf  Research papers about Machine Translation:   A Recursive Recurrent Neural Network for Statistical Machine Translation  Sequence to Sequence Learning with Neural Networks  Joint Language and Translation Modeling with Recurrent Neural Networks", 
            "title": "Machine Translation"
        }, 
        {
            "location": "/rnn/#speech-recognition", 
            "text": "Given an input sequence of acoustic signals from a sound wave, we can predict a sequence of phonetic segments together with their probabilities.  Research papers about Speech Recognition:  Towards End-to-End Speech Recognition with Recurrent Neural Networks", 
            "title": "Speech Recognition"
        }, 
        {
            "location": "/rnn/#generating-image-descriptions", 
            "text": "Together with convolutional Neural Networks, RNNs have been used as part of a model to generate descriptions for unlabeled images. It\u2019s quite amazing how well this seems to work. The combined model even aligns the generated words with features found in the images.  Deep Visual-Semantic Alignments for Generating Image Descriptions\nDeep Visual-Semantic Alignments for Generating Image Descriptions. Source: http://cs.stanford.edu/people/karpathy/deepimagesent/", 
            "title": "Generating Image Descriptions"
        }, 
        {
            "location": "/rnn/#training-rnns", 
            "text": "Training a RNN is similar to training a traditional Neural Network. We also use the backpropagation algorithm, but with a little twist. Because the parameters are shared by all time steps in the network, the gradient at each output depends not only on the calculations of the current time step, but also the previous time steps. For example, in order to calculate the gradient at t=4 we would need to backpropagate 3 steps and sum up the gradients. This is called Backpropagation Through Time (BPTT). If this doesn\u2019t make a whole lot of sense yet, don\u2019t worry, we\u2019ll have a whole post on the gory details. For now, just be aware of the fact that vanilla RNNs trained with BPTT have difficulties learning long-term dependencies (e.g. dependencies between steps that are far apart) due to what is called the vanishing/exploding gradient problem. There exists some machinery to deal with these problems, and certain types of RNNs (like LSTMs) were specifically designed to get around them.", 
            "title": "Training RNNs"
        }, 
        {
            "location": "/rnn/#rnn-extensions", 
            "text": "Over the years researchers have developed more sophisticated types of RNNs to deal with some of the shortcomings of the vanilla RNN model. We will cover them in more detail in a later post, but I want this section to serve as a brief overview so that you are familiar with the taxonomy of models.  Bidirectional RNNs are based on the idea that the output at time t may not only depend on the previous elements in the sequence, but also future elements. For example, to predict a missing word in a sequence you want to look at both the left and the right context. Bidirectional RNNs are quite simple. They are just two RNNs stacked on top of each other. The output is then computed based on the hidden state of both RNNs.", 
            "title": "RNN Extensions"
        }, 
        {
            "location": "/rnn/#bidirectional-rnn", 
            "text": "Deep (Bidirectional) RNNs are similar to Bidirectional RNNs, only that we now have multiple layers per time step. In practice this gives us a higher learning capacity (but we also need a lot of training data).", 
            "title": "Bidirectional RNN"
        }, 
        {
            "location": "/rnn/#deep-bidirectional-rnn", 
            "text": "LSTM networks are quite popular these days and we briefly talked about them above. LSTMs don\u2019t have a fundamentally different architecture from RNNs, but they use a different function to compute the hidden state. The memory in LSTMs are called cells and you can think of them as black boxes that take as input the previous state h_{t-1} and current input x_t. Internally these cells  decide what to keep in (and what to erase from) memory. They then combine the previous state, the current memory, and the input. It turns out that these types of units are very efficient at capturing long-term dependencies. LSTMs can be quite confusing in the beginning but if you\u2019re interested in learning more this post has an excellent explanation.", 
            "title": "Deep Bidirectional RNN"
        }, 
        {
            "location": "/rnn/#conclusion", 
            "text": "So far so good. I hope you\u2019ve gotten a basic understanding of what RNNs are and what they can do. In the next post we\u2019ll implement a first version of our language model RNN using Python and Theano. Please leave questions in the comments!", 
            "title": "Conclusion"
        }, 
        {
            "location": "/cnn/", 
            "text": "Convolutional Neural Networks\n\n\nConvolutional Neural Networks are very similar to ordinary Neural Networks from the previous chapter: they are made up of neurons that have learnable weights and biases. Each neuron receives some inputs, performs a dot product and optionally follows it with a non-linearity. The whole network still expresses a single differentiable score function: from the raw image pixels on one end to class scores at the other. And they still have a loss function (e.g. SVM/Softmax) on the last (fully-connected) layer and all the tips/tricks we developed for learning regular Neural Networks still apply.\n\n\nSo what does change? ConvNet architectures make the explicit assumption that the inputs are images, which allows us to encode certain properties into the architecture. These then make the forward function more efficient to implement and vastly reduce the amount of parameters in the network.", 
            "title": "Convolutional Neural Network"
        }, 
        {
            "location": "/cnn/#convolutional-neural-networks", 
            "text": "Convolutional Neural Networks are very similar to ordinary Neural Networks from the previous chapter: they are made up of neurons that have learnable weights and biases. Each neuron receives some inputs, performs a dot product and optionally follows it with a non-linearity. The whole network still expresses a single differentiable score function: from the raw image pixels on one end to class scores at the other. And they still have a loss function (e.g. SVM/Softmax) on the last (fully-connected) layer and all the tips/tricks we developed for learning regular Neural Networks still apply.  So what does change? ConvNet architectures make the explicit assumption that the inputs are images, which allows us to encode certain properties into the architecture. These then make the forward function more efficient to implement and vastly reduce the amount of parameters in the network.", 
            "title": "Convolutional Neural Networks"
        }, 
        {
            "location": "/feed/", 
            "text": "Latest News", 
            "title": "<span class='fa fa-rss'></span> News"
        }, 
        {
            "location": "/feed/#latest-news", 
            "text": "", 
            "title": "Latest News"
        }
    ]
}